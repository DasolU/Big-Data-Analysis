{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML 종류\n",
    "- 머신러닝이란? f(x)=y의 함수 f\n",
    "    - 주어진 데이터 속에서 데이터의 특징을 찾아내는 함수 f를 만드는 것\n",
    "- 지도학습: 입력 변수(x)와 출력 변수(y) 간의 관계에 대해 모델링 하는 것\n",
    "    - x(독립변수, feature)로 y(종속변수, 반응변수) 예측/분류\n",
    "    - 종류: 회귀분석, 분류(class)\n",
    "- 비지도학습: 입력 변수(x)간의 관계에 대해 모델링 하는 것\n",
    "    - x로 x의 패턴 분석\n",
    "    - 군집 분석, PCA, \n",
    "- 강화학습:\n",
    "    - 많은 시뮬레이션을 통해 현재 선택이 먼 미래에 보상이 최대가 되도록 학습\n",
    "    - 구성 요소: Agent, action, reward\n",
    "- 종류:\n",
    "    - 선형 회귀분석(linear regression)\n",
    "    - 의사결정나무(decision tree)\n",
    "        - 독립 변수 조건에 따라 종속 변수 분리\n",
    "        - overfitting 잘 일어남\n",
    "        - 앙상블 러닝의 기초\n",
    "    - KNN(k-nearest neighbor)\n",
    "        - 새로 들어온 데이터 주변 k개 데이터의 class 중 가까운 class 찾는 것\n",
    "        - K: 사람이 지정하는 hyper parameter\n",
    "    - Neural Network\n",
    "        - 입력, 은닉, 출력 층으로 구성\n",
    "        - 각 층을 연결하는 노드의 가중치를 업데이트하며 학습\n",
    "        - overfitting 잘 일어남, 시간이 오래 걸림\n",
    "    - SVM(Support Vector Machine)\n",
    "        - class 간 거리(margin)가 최대가 되도록 decision boundary를 만드는 방법\n",
    "        - 단점: 학습 시간이 오래 걸림\n",
    "    - Ensemble Learning\n",
    "        - 여러 개의 모델(주로 decision tree)를 결합하여 사용하는 모델\n",
    "        - 성능 가장 좋다. 각종 대회에 우승 모델.\n",
    "    - k-means clustering\n",
    "        - labeled 데이터 없이 k개 군집 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 주요 모델\n",
    "\n",
    "- 딥러닝이란? (graphical representation learning)\n",
    "    - 다양한 layer 층을 통해 복잡한 데이터의 학습이 가능토록 함\n",
    "- 딥러닝의 도래\n",
    "    - Neural Network의 단점으로 SVM이 사용되어왔다.\n",
    "    - 하지만 알고리즘, GPU의 발전으로 deep learning이 부흥 시작\n",
    "    - 이미지 분류 기존 모델:\n",
    "        - 2D 이미지에서 각 픽셀 값을 하나의 벡터로 늘어트려 독립 변수로 사용\n",
    "        - 이미지 데이터에서 서로 가까이 있는 픽셀들이 서로 독립이 아니기 때문에,\n",
    "        - 독립 변수들이 각각 독립이라는 기본 가정에 어긋남\n",
    "    - 현재 모델:\n",
    "        - 지역별 특징을 뽑고 나중에 늘어트려 사용\n",
    "        - CNN, RNN, AutoEncoder\n",
    "        - 네트워크 구조의 발전\n",
    "            - ResNET, DenseNET\n",
    "- 딥러닝 주요 모델:\n",
    "    - GAN (Generative Adversarial Network)\n",
    "        - Generator: 생성\n",
    "        - Discriminator: 평가\n",
    "        - method:\n",
    "            - Discriminator 학습: 진짜는 진짜 가짜는 가짜로 판별하도록 학습\n",
    "            - Generator 학습: 가짜를 discriminator가 구분 못하도록 학습\n",
    "        - 예시)\n",
    "            - BigGAN, CycleGAN, Photo style transfer, High-res in-painting\n",
    "    - 강화학습\n",
    "        - Q-learning\n",
    "            - action에 따라 Q값이 나오고, 높은 Q값을 주는 action을 선택\n",
    "        - DQN\n",
    "            - Q-learning+Deep learning\n",
    "            - Deep reinforcement learning의 시초 \n",
    "        - 단점:\n",
    "            - 수 많은 시뮬레이션을 수행하는데 걸리는 시간 단축\n",
    "            - reward가 매우 sparse한 경우\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌모형 적합성 평가 및 실험 설계\n",
    "\n",
    "- 간단한 모델일수록 underfitting\n",
    "- 복잡한 모델일수록 overfitting(학습데이터에 잘 맞는다)\n",
    "\n",
    "- 데이터 분할\n",
    "    - training + validation + test\n",
    "        - 비율: \n",
    "        - training: 모형 f 추정에 사용\n",
    "        - test: 모형의 성능 평가\n",
    "        - validation: 추정한 모형이 적합한지 검증.\n",
    "            - validation을 보고 모형의 hyper parameter를 조정한다.\n",
    "- 실험 설계\n",
    "    - k-fold cross validation\n",
    "        - 데이터가 애매하게 많은 경우 모형의 적합성을 보다 객관적으로 평가할 때 사용\n",
    "        - 여러 fold를 평가한 뒤 평균낸다.\n",
    "    - LOOCV (leave-one-out cross validation)\n",
    "        - 데이터 수가 극단적으로 적을 때 무조건 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌과적합\n",
    "- 발생 경우?\n",
    "    - 복잡한 모델일수록, 데이터가 적을 수록 발생\n",
    "    - 근본적 해결책은 없으나, 완화/방지 기술 발전 중\n",
    "- 구성:\n",
    "    - recudible error + irrecudible error(엡실론)\n",
    "    - recudible error = 분산+편파성\n",
    "        - 추정한 모델의 분산: \n",
    "            - 전체 데이터 집합 중 다른 학습 데이터를 이용했을 때, 함수가 변하는 정도\n",
    "            - 복잡한 모형일수록 높다\n",
    "        - 편파성(bias)\n",
    "            - 예측한 모델과 실제 모델의 차이\n",
    "            - 간단한 모형일 수록 높다\n",
    "- 분산과 편파성의 tradeoff dilemma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
