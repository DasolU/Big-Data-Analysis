{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀\n",
    "- 변수의 유의성\n",
    "    - p-value를 통해 파악\n",
    "- 해석\n",
    "    - coefficient: ~단위 증가한다.\n",
    "\n",
    "## Decision Tree\n",
    "- 독립 변수의 조건에 따라 종속변수 분리\n",
    "\n",
    "## Ensemble은 해석이 어렵다.\n",
    "따라서 모델 선택시 목적에 따라 달라진다.\n",
    "\n",
    "1.정확도 낮고 설명하기 쉬운 모델\n",
    "\n",
    "2.정확도 높고 설명하기 어려운 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "Ensemble learning 모델들은 중요 feature를 추출할 수 있는 알고리즘 내장되어있다.\n",
    "\n",
    "\n",
    "### Feature importance 측정 기준\n",
    "- weight: 변수 별 데이터를 분리하는데 쓰인 횟수\n",
    "- cover: 변수를 사용하여 데이터를 분리하였을 때, 분리된 데이터의 수로 가중치 (weight 보다 합리적)\n",
    "- gain: feature를 사용했을 때 줄어드는 평균적인 training loss\n",
    "\n",
    "### Feature importance 문제점\n",
    "- 중요성만 알고 양/음/얼마나 중요한지 알 수 없다.\n",
    "- 측정 기준 별로 중요한 변수가 다르다.\n",
    "\n",
    "### Feature importance 좋고 나쁨의 기준\n",
    "- consistency: 특정 feature가 영향이 많이 가도록 모델을 수정한 결과에도 해당 feature의 중요도가 줄어들지 않아야 한다.\n",
    "- **대부분 featuresms inconsistency한 문제**가 발생\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌Shap value\n",
    "- consistency가 있다.\n",
    "- 변수 해석에 큰 도움이 되는 지표이다.\n",
    "\n",
    "- 방법:\n",
    "    - 특정 관측치의 n번째 feature로 인해 발생하는 실제 예측치와 평균 예측치의 차이를 평균한 것\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
