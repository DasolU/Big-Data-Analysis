{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature의 중요성\n",
    "- Feature만 좋으면 어떤 머신러닝 알고리즘이라도 예측 성능이 높다.\n",
    "\n",
    "\n",
    "# Feature selection 정리\n",
    "- 다중 선형 회귀 모델의 귀무가설의 한계\n",
    "    - 다중 선형 회귀 모델의 귀무가설은 기각하기 너무 쉽다.\n",
    "    - 변수 개수가 많아질수록 귀무가설을 기각하기 쉬워진다.\n",
    "- 다중공선성\n",
    "    - y를 설명하는 설명력을 중복으로 가저가시 못하기 때문에 발생\n",
    "    - 잘못된 변수 해석, 예측 정확도 하락 야기\n",
    "    \n",
    "- CNN vs. NN\n",
    "    - 차이점: feature만 다를 뿐이다.\n",
    "    - CNN이 항상 좋다\n",
    "        - 📌이유: CNN에서 더 좋은 feature(graphical feature)를 뽑았기 때문에!\n",
    "\n",
    "- 중요 변수 100개 >> 모든 변수\n",
    "- 모델 선택(변수 선택)\n",
    "    - 이유: 변수 개수가 증가할수록 변수의 총 조합은 매우 증가\n",
    "\n",
    "- 계수 축소법\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
